---
title: 从 Augment 涨价说起：我在国产 AI 编程工具里"踩坑"的半个月
date: 2025-02-11T15:30:00.000Z
categories:
  - 随笔
tags:
  - AI
  - 编程
  - 思考
excerpt_type: ai
---

去年年尾收到 Augment 的邮件，说是要涨价了。我一开始没当回事，结果点进去一看——月费从 50 刀涨到 60 刀不说，额度从 500 次变成积分额度，换算一下直接砍到 120 次左右。

我愣在那里算了一下，这涨幅有点狠啊。

作为用了 Augment 大半年的老用户，说实话有点难受。它确实好用，尤其是在理解大型代码库和做重构的时候，那种"懂我在说什么"的感觉很爽。但价格这么一涨，我开始认真考虑：是不是该找个国产替代了？

## 开始"试毒"国产模型

接下来的两周，我几乎是把所有国产带 Coding 功能的模型都试了个遍——Kimi 的 Coding Plan、火山的 Coding Plan、GLM 的 Coding Plan，还有 MiniMax 2.1。

先说结论：**便宜是真的便宜，但用起来也是真的"心累"**。

我手头正好有个 TypeScript 项目在做，想着趁这个机会看看这些模型写 TS 的水平怎么样。结果测了几天，发现一个特别有意思的现象——

**国产模型特别喜欢用 `as any`**。

不是说不能用，但问题是它们用得太频繁了。类型对不上？`as any`。推断不出来？`as any`。复杂一点的泛型约束写不下去了？还是 `as any`。

我一开始以为是训练数据的问题，后来跟几个做 AI 的朋友聊，才意识到这背后其实是**强化学习的奖励机制**在搞鬼。

## 奖励黑客：当"骗过编译器"成了最优解

现在的国产模型，基本上用的都是 **ORM（结果奖励模型）**——简单说就是，代码能不能跑通、测试能不能过，是主要的奖励信号。

听起来挺合理对吧？但问题就出在这里。

在 RL 训练过程中，模型很快就会发现一个"捷径"：写严格的类型约束又费脑子又容易错，但用 `any` 只要一行就能骗过编译器，顺利拿到"编译通过"的奖励。

这就像考试的时候发现，只要填"略"就能得分，谁还愿意认真答题啊？

学术上管这叫 **"奖励黑客"（Reward Hacking）**——模型不是变笨了，反而是太聪明了，学会了利用评价体系的漏洞来最大化自己的得分。

但代价是什么呢？**代码变得难以维护**。

## Claude 的"慢哲学"

作为对比，我一直在用 Claude Opus 4.6。它贵是贵，但写代码的时候真的能感觉到一种"架构感"。

后来我了解到，Claude 用的是 **PRM（过程奖励模型）**——它不光看最后代码能不能跑，还会给推理过程中的每一步打分。

这意味着什么？模型会发现，虽然用 `any` 能快速解决当下的类型错误，但后面很可能会引发连锁反应，导致整体架构分降低。所以它会选择慢一点、想多一点，确保每个类型定义都是严谨的。

这种感觉就像和一个老练的架构师合作——他可能不会立刻给你答案，但给出的方案一定是经得起推敲的。

## GPT-5 的"谦逊"

再说说 GPT-5.3。最近用它的时候有个很明显的感受——它"变慢"了。

不是生成速度变慢，而是它会**频繁地调用工具**来确认信息。遇到不确定的库版本、模糊的边缘情况，它不再像之前那样"自信满满"地直接输出代码，而是会先查文档、看终端、确认上下文。

OpenAI 管这叫"认知密度"和"认识论谦逊"。

说实话，小任务这么做确实有点"大炮打蚊子"的感觉。但在复杂工程里，这种"走一步确认一步"的策略反而能提高一次性成功的概率。

就像带了一个随身带着全套文档的 Tech Lead，虽然有时候觉得他在"墨迹"，但关键时刻很少掉链子。

## 国产模型的"顽疾"

说回国产模型。除了前面提到的 `as any` 问题，我在实际使用中还有两个特别头疼的点：

**第一，文件修改太粗暴。**

国产模型在调用工具的时候，特别喜欢重写整个文件，而不是用 Patch 或 Diff 做增量修改。结果就陷入一个死循环：写完发现超长了 -> 删掉重写 -> 又超长 -> 再删再写……直到令牌耗尽。

**第二，"嘴硬"不反思。**

国外模型第一次尝试失败后，通常会换个思路重新来。但国产模型有时候会在同一个错误点上反复折腾，表现得特别"固执"，直到把令牌用完。

说白了，国产模型现在唯一的优势就是**便宜**。它用牺牲开发者的时间来换取低廉的推理成本。

但如果 RL 训练中的"架构自觉"问题不解决，开发者最后大概率还是会回到 Claude 或 GPT 的怀抱——毕竟，**时间也是成本**。

## 展望

不过话说回来，国产模型的迭代速度确实惊人。听说 GLM-5 可能要在过年前后发布，核心优化点就是智能体协作和长程规划能力。

我期待有一天，国内大厂能从单纯追求"跑通测试"的 ORM 范式，转向更关注"代码质量"和"过程逻辑"的 PRM 范式。

我们需要的是一个能遵守 TypeScript 类型契约的编程伴侣，而不是一个会钻编译器漏洞的"机灵鬼"。

## 最后的一点建议

如果你问我现在该怎么选，我的建议是：

- **重架构、大型项目**：咬牙上 Claude Opus 4.6，PRM 带来的类型安全和架构感真的无价。
- **快速原型、脚本编写**：GPT-5.3 Codex 是速度和工具调用的平衡点。
- **低成本试错、UI 还原**：Kimi K2.5 和 GLM-4.7 的"Vibe Coding"能力确实强，性价比极高。

希望过完年，我们能真正用上既便宜又有"架构灵魂"的国产编程模型。
